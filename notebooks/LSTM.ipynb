{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # it is used for the time series management dataset.\n",
    "import numpy as np # it is used to manage collections of values in the pandas dataframe.\n",
    "import json \n",
    "import datetime as dt\n",
    "import warnings\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "stop = EarlyStopping(monitor='root_mean_squared_error', patience=30, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df_grouped = pd.read_pickle('../../monthly/grouped_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter points from original dataset to geojson coordinates related to river positions.\n",
    "coords = json.load(open('../app/static/data/points_new_fill.geojson', 'r'))\n",
    "lats = []\n",
    "longs = []\n",
    "for coord in coords['features'][:]:\n",
    "    sample = coord['geometry']['coordinates']\n",
    "    lats.append(sample[1])\n",
    "    longs.append(sample[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = json.load(open('../samples/source_mounth.json', 'r'))\n",
    "sources_rivers = []\n",
    "names = []\n",
    "mounths_rivers = []\n",
    "italy_sources_mounths = pd.DataFrame()\n",
    "for key in datasource.keys():\n",
    "    sources_rivers.append(datasource[key]['source'])\n",
    "    mounths_rivers.append(datasource[key]['mounth'])\n",
    "    names.append(key)\n",
    "\n",
    "italy_sources_mounths['names'] = names\n",
    "italy_sources_mounths['mounth'] = mounths_rivers\n",
    "italy_sources_mounths['source'] = sources_rivers\n",
    "italy_sources_mounths['number_value'] = [i for i in range(0, len(italy_sources_mounths))]\n",
    "italy_sources_mounths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaries with the dataframe for each river\n",
    "sources = {}\n",
    "mounths = {}\n",
    "names = list(italy_sources_mounths.names)\n",
    "for i in range(len(italy_sources_mounths)):\n",
    "    name = names[i]\n",
    "    sources[name] = df[df['coords'] == tuple(italy_sources_mounths['source'][i])]\n",
    "    mounths[name] = df[df['coords'] == tuple(italy_sources_mounths['mounth'][i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sources:\n",
    "    #sources[name] = sources[name].drop(columns=['coords'], inplace=False)\n",
    "    sources[name] = sources[name].set_index('time')\n",
    "    #mounths[name] = mounths[name].drop(columns=['coords'], inplace=False)\n",
    "    mounths[name] = mounths[name].set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion from a single column dataframe to two arrays, one with the observations and one with the label to predict\n",
    "def df_to_supervised_discharge(df, window_size=12):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = [r for r in df_as_np[i:i+window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size][0]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion from a single column dataframe to two arrays, one with the observations and one with the label to predict\n",
    "def df_to_supervised_temperature(df, window_size=12):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = [r for r in df_as_np[i:i+window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size][0]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column with seconds to do the sin cos trick\n",
    "for name in sources:\n",
    "    sources[name]['secs'] = sources[name].index.map(pd.Timestamp.timestamp)\n",
    "    mounths[name]['secs'] = mounths[name].index.map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "day = 60*60*24\n",
    "year = 365.2425*day\n",
    "for name in sources:\n",
    "    sources[name]['year_sin'] = np.sin(sources[name]['secs']*(2*np.pi/year))\n",
    "    mounths[name]['year_sin'] = np.sin(mounths[name]['secs']*(2*np.pi/year))\n",
    "\n",
    "    sources[name]['year_cos'] = np.cos(sources[name]['secs']*(2*np.pi/year))\n",
    "    mounths[name]['year_cos'] = np.cos(mounths[name]['secs']*(2*np.pi/year))\n",
    "\n",
    "    sources[name] = sources[name].drop(columns=['secs'])\n",
    "    mounths[name] = mounths[name].drop(columns=['secs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources['Tevere '].drop(columns=['prec', 'discharge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sources:\n",
    "    src = sources[name].drop(columns=['prec', 'discharge', 'coords'])\n",
    "    #creating the x tensor and the labels\n",
    "    X, y = df_to_supervised_temperature(src)\n",
    "\n",
    "    #splitting\n",
    "    n = len(X)\n",
    "    X_train, y_train = X[0:int(n*0.7)], y[0:int(n*0.7)]\n",
    "    X_val, y_val = X[int(n*0.7):int(n*0.9)], y[int(n*0.7):int(n*0.9)]\n",
    "    X_test, y_test = X[int(n*0.9):], y[int(n*0.9):]\n",
    "\n",
    "    model_tmp_src = Sequential()\n",
    "    model_tmp_src.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model_tmp_src.add(Dense(12))\n",
    "    model_tmp_src.add(Dense(1))\n",
    "\n",
    "    #model2.summary()\n",
    "    model_tmp_src.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
    "    model_tmp_src.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, verbose=0, callbacks=[stop])\n",
    "\n",
    "    test_predictions = model_tmp_src.predict(X_test).flatten()\n",
    "    test_results = pd.DataFrame(data={'Preds': test_predictions, 'Actuals':y_test})\n",
    "    mse = mean_squared_error(test_predictions, y_test)\n",
    "    mae = mean_absolute_error(test_predictions, y_test)\n",
    "    print('Test on sources for '+name)\n",
    "    print('MSE: %.3f' % mse)\n",
    "    print('MAE: %.3f' % mae)\n",
    "\n",
    "    plt.plot(test_results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sources:\n",
    "    src = mounths[name].drop(columns=['prec', 'discharge', 'coords'])\n",
    "    #creating the x tensor and the labels\n",
    "    X, y = df_to_supervised_temperature(src)\n",
    "\n",
    "    #splitting\n",
    "    n = len(X)\n",
    "    X_train, y_train = X[0:int(n*0.7)], y[0:int(n*0.7)]\n",
    "    X_val, y_val = X[int(n*0.7):int(n*0.9)], y[int(n*0.7):int(n*0.9)]\n",
    "    X_test, y_test = X[int(n*0.9):], y[int(n*0.9):]\n",
    "\n",
    "    model_tmp_mth = Sequential()\n",
    "    model_tmp_mth.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model_tmp_mth.add(Dense(12))\n",
    "    model_tmp_mth.add(Dense(1))\n",
    "\n",
    "    #model2.summary()\n",
    "    model_tmp_mth.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
    "    model_tmp_mth.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, verbose=0)\n",
    "    test_predictions = model_tmp_mth.predict(X_test).flatten()\n",
    "    test_results = pd.DataFrame(data={'Preds': test_predictions, 'Actuals':y_test})\n",
    "    mse = mean_squared_error(test_predictions, y_test)\n",
    "    mae = mean_absolute_error(test_predictions, y_test)\n",
    "    print('Test on mouths for '+name)\n",
    "    print('MSE: %.3f' % mse)\n",
    "    print('MAE: %.3f' % mae)\n",
    "    plt.plot(test_predictions, label='predictions')\n",
    "    plt.plot(y_test, label='actual')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sources:\n",
    "    src = sources[name].drop(columns=['prec'])\n",
    "    #creating the x tensor and the labels\n",
    "    X, y = df_to_supervised_discharge(src)\n",
    "\n",
    "    #splitting\n",
    "    n = len(X)\n",
    "    X_train, y_train = X[0:int(n*0.7)], y[0:int(n*0.7)]\n",
    "    X_val, y_val = X[int(n*0.7):int(n*0.9)], y[int(n*0.7):int(n*0.9)]\n",
    "    X_test, y_test = X[int(n*0.9):], y[int(n*0.9):]\n",
    "    #normalizing\n",
    "    X_mean = X_train.mean()\n",
    "    X_std = X_train.std()\n",
    "    X_train_sc = (X_train - X_mean) / X_std\n",
    "    X_val_sc = (X_val - X_mean) / X_std\n",
    "    X_test_sc = (X_test - X_mean) / X_std\n",
    "\n",
    "\n",
    "    y_mean = y_train.mean()\n",
    "    y_std = y_train.std()\n",
    "    y_train_sc = (y_train - X_mean) / X_std\n",
    "    y_val_sc = (y_val - X_mean) / X_std\n",
    "    y_test_sc = (y_test - X_mean) / X_std\n",
    "    \n",
    "    model_dis_src = Sequential()\n",
    "    model_dis_src.add(LSTM(32, input_shape=(X_train_sc.shape[1], X_train_sc.shape[2])))\n",
    "    model_dis_src.add(Dense(12))\n",
    "    model_dis_src.add(Dense(1))\n",
    "\n",
    "    #model2.summary()\n",
    "    model_dis_src.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
    "    model_dis_src.fit(X_train_sc, y_train_sc, validation_data=(X_val_sc, y_val_sc), epochs=30, verbose=0)\n",
    "\n",
    "    test_predictions = model_dis_src.predict(X_test_sc).flatten()\n",
    "    test_predictions = (test_predictions*X_std)+X_mean\n",
    "    test_results = pd.DataFrame(data={'Preds': test_predictions, 'Actuals':y_test})\n",
    "    mse = mean_squared_error(test_predictions, y_test)\n",
    "    mae = mean_absolute_error(test_predictions, y_test)\n",
    "    print('Test on mouths for '+name)\n",
    "    print('MSE: %.3f' % mse)\n",
    "    print('MAE: %.3f' % mae)\n",
    "    plt.plot(test_results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in mounths:\n",
    "    src = mounths[name].drop(columns=['prec'])\n",
    "    #creating the x tensor and the labels\n",
    "    X, y = df_to_supervised_discharge(src)\n",
    "\n",
    "    #splitting\n",
    "    n = len(X)\n",
    "    X_train, y_train = X[0:int(n*0.7)], y[0:int(n*0.7)]\n",
    "    X_val, y_val = X[int(n*0.7):int(n*0.9)], y[int(n*0.7):int(n*0.9)]\n",
    "    X_test, y_test = X[int(n*0.9):], y[int(n*0.9):]\n",
    "    #normalizing\n",
    "    X_mean = X_train.mean()\n",
    "    X_std = X_train.std()\n",
    "    X_train_sc = (X_train - X_mean) / X_std\n",
    "    X_val_sc = (X_val - X_mean) / X_std\n",
    "    X_test_sc = (X_test - X_mean) / X_std\n",
    "\n",
    "\n",
    "    y_mean = y_train.mean()\n",
    "    y_std = y_train.std()\n",
    "    y_train_sc = (y_train - y_mean) / y_std\n",
    "    y_val_sc = (y_val - y_mean) / y_std\n",
    "    y_test_sc = (y_test - y_mean) / y_std\n",
    "    \n",
    "    model_dis_mth = Sequential()\n",
    "    model_dis_mth.add(LSTM(32, input_shape=(X_train_sc.shape[1], X_train_sc.shape[2])))\n",
    "    model_dis_mth.add(Dense(12))\n",
    "    model_dis_mth.add(Dense(1))\n",
    "\n",
    "    #model2.summary()\n",
    "    model_dis_mth.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
    "    model_dis_mth.fit(X_train_sc, y_train_sc, validation_data=(X_val_sc, y_val_sc), epochs=30, verbose=0)\n",
    "\n",
    "    test_predictions = model_dis_mth.predict(X_test_sc).flatten()\n",
    "    test_predictions = (test_predictions*X_std)+X_mean\n",
    "    test_results = pd.DataFrame(data={'Preds': test_predictions, 'Actuals':y_test})\n",
    "    rmse = math.sqrt(mean_squared_error(test_predictions, y_test))\n",
    "    print('Test on mouths for '+name)\n",
    "    print('RMSE: %.3f' % rmse)\n",
    "    plt.plot(test_results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "stop = EarlyStopping(monitor='root_mean_squared_error', patience=30, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_future_df(df, window_size=12):\n",
    "    last_time = df.index.values[-1]\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    i = len(df_as_np)-window_size\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    return np.array(X), last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_row_tmp(X, last_time, predicted_val):\n",
    "    #create the new row basically\n",
    "    X_new = []\n",
    "    day = 60*60*24\n",
    "    year = 365.2425*day\n",
    "    next_month = pd.Timestamp(last_time) + pd.DateOffset(months=1)\n",
    "    sin = np.sin(next_month.timestamp()*(2*np.pi/year))\n",
    "    cos = np.cos(next_month.timestamp()*(2*np.pi/year))\n",
    "    row = [predicted_val, sin, cos]\n",
    "    for i in range(1, len(X[0])):\n",
    "        X_new.append(X[0][i])\n",
    "    X_new.append(row)\n",
    "    return np.array([X_new]), next_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row_dis(X, last_time, predicted_val_tmp, predicted_val_dis):\n",
    "    #create the new row basically\n",
    "    X_new = []\n",
    "    day = 60*60*24\n",
    "    year = 365.2425*day\n",
    "    next_month = pd.Timestamp(last_time) + pd.DateOffset(months=1)\n",
    "    sin = np.sin(next_month.timestamp()*(2*np.pi/year))\n",
    "    cos = np.cos(next_month.timestamp()*(2*np.pi/year))\n",
    "    row = [predicted_val_dis, predicted_val_tmp, sin, cos]\n",
    "    for i in range(1, len(X[0])):\n",
    "        X_new.append(X[0][i])\n",
    "    X_new.append(row)\n",
    "    return np.array([X_new]), next_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tmp = sources['Ticino'].drop(columns=['prec', 'discharge', 'coords'])\n",
    "src_dis = sources['Ticino'].drop(columns=['prec', 'coords'])\n",
    "X_tmp, last_time = create_future_df(src_tmp)\n",
    "X_dis, _ = create_future_df(src_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the x tensor and the labels\n",
    "X, y = df_to_supervised_temperature(src_tmp)\n",
    "\n",
    "#splitting\n",
    "n = len(X)\n",
    "X_train, y_train = X[0:int(n*0.7)], y[0:int(n*0.7)]\n",
    "X_val, y_val = X[int(n*0.7):], y[int(n*0.7):]\n",
    "\n",
    "model_tmp_src = Sequential()\n",
    "model_tmp_src.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_tmp_src.add(Dense(12))\n",
    "model_tmp_src.add(Dense(1))\n",
    "\n",
    "model_tmp_src.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
    "model_tmp_src.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the x tensor and the labels\n",
    "X, y = df_to_supervised_discharge(src_dis)\n",
    "\n",
    "#splitting\n",
    "n = len(X)\n",
    "X_train, y_train = X[0:int(n*0.7)], y[0:int(n*0.7)]\n",
    "X_val, y_val = X[int(n*0.7):], y[int(n*0.7):]\n",
    "\n",
    "#normalizing\n",
    "X_mean = X_train.mean()\n",
    "X_std = X_train.std()\n",
    "X_train_sc = (X_train - X_mean) / X_std\n",
    "X_val_sc = (X_val - X_mean) / X_std\n",
    "\n",
    "\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "y_train_sc = (y_train - y_mean) / y_std\n",
    "y_val_sc = (y_val - y_mean) / y_std\n",
    "\n",
    "model_dis_src = Sequential()\n",
    "model_dis_src.add(LSTM(32, input_shape=(X_train_sc.shape[1], X_train_sc.shape[2])))\n",
    "model_dis_src.add(Dense(12))\n",
    "model_dis_src.add(Dense(1, activation='softplus'))\n",
    "\n",
    "model_dis_src.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])\n",
    "model_dis_src.fit(X_train_sc, y_train_sc, validation_data=(X_val_sc, y_val_sc), epochs=1000, verbose=0, callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 12\n",
    "tmp_pred_ls = []\n",
    "dis_pred_ls = []\n",
    "time = []\n",
    "for i in range(n_pred):\n",
    "    tmp_pred = model_tmp_src.predict(X_tmp).flatten()[0]\n",
    "    dis_pred = model_dis_src.predict(X_dis).flatten()[0]\n",
    "    tmp_pred_ls.append(tmp_pred)\n",
    "    dis_pred_ls.append(dis_pred)\n",
    "    time.append(last_time)\n",
    "    X_tmp, _ = append_row_tmp(X_tmp, last_time, tmp_pred)\n",
    "    X_dis, last_time = append_row_dis(X_dis, last_time, tmp_pred, dis_pred)\n",
    "\n",
    "data = {'date': time, 'dis':dis_pred_ls, 'temp':tmp_pred_ls}\n",
    "new_df = pd.DataFrame(data=data)\n",
    "print(new_df.head())\n",
    "\n",
    "#i already have the model trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>discharge</th>\n",
       "      <th>temp</th>\n",
       "      <th>prec</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">(40.519886, 8.314602)</th>\n",
       "      <th>2011-01-15</th>\n",
       "      <td>0.380702</td>\n",
       "      <td>12.225464</td>\n",
       "      <td>1.492938e-05</td>\n",
       "      <td>0.239478</td>\n",
       "      <td>0.970902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-15</th>\n",
       "      <td>0.405744</td>\n",
       "      <td>9.720506</td>\n",
       "      <td>4.443793e-05</td>\n",
       "      <td>0.699798</td>\n",
       "      <td>0.714341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-15</th>\n",
       "      <td>0.229209</td>\n",
       "      <td>10.260750</td>\n",
       "      <td>1.142119e-05</td>\n",
       "      <td>0.951104</td>\n",
       "      <td>0.308870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-15</th>\n",
       "      <td>0.167334</td>\n",
       "      <td>14.710362</td>\n",
       "      <td>1.063244e-05</td>\n",
       "      <td>0.976054</td>\n",
       "      <td>-0.217529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-15</th>\n",
       "      <td>0.120527</td>\n",
       "      <td>16.981652</td>\n",
       "      <td>8.759512e-07</td>\n",
       "      <td>0.741586</td>\n",
       "      <td>-0.670858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  discharge       temp          prec  \\\n",
       "coords                time                                             \n",
       "(40.519886, 8.314602) 2011-01-15   0.380702  12.225464  1.492938e-05   \n",
       "                      2011-02-15   0.405744   9.720506  4.443793e-05   \n",
       "                      2011-03-15   0.229209  10.260750  1.142119e-05   \n",
       "                      2011-04-15   0.167334  14.710362  1.063244e-05   \n",
       "                      2011-05-15   0.120527  16.981652  8.759512e-07   \n",
       "\n",
       "                                  year_sin  year_cos  \n",
       "coords                time                            \n",
       "(40.519886, 8.314602) 2011-01-15  0.239478  0.970902  \n",
       "                      2011-02-15  0.699798  0.714341  \n",
       "                      2011-03-15  0.951104  0.308870  \n",
       "                      2011-04-15  0.976054 -0.217529  \n",
       "                      2011-05-15  0.741586 -0.670858  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe for each point\n",
    "day = 60*60*24\n",
    "year = 365.2425*day\n",
    "\n",
    "df_prediction = df_grouped\n",
    "df_prediction = df_prediction.set_index('time')\n",
    "df_prediction['secs'] = df_prediction.index.map(pd.Timestamp.timestamp)\n",
    "\n",
    "df_prediction['year_sin'] = np.sin(df_prediction['secs']*(2*np.pi/year))\n",
    "df_prediction['year_cos'] = np.cos(df_prediction['secs']*(2*np.pi/year))\n",
    "df_prediction = df_prediction.reset_index()\n",
    "df_prediction = df_prediction.set_index(['coords', 'time'])\n",
    "\n",
    "df_prediction = df_prediction.drop(columns=['secs'])\n",
    "df_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on each coordinate i do the prediction\n",
    "parent = 'E:/francesco/UNI/HDS/models'\n",
    "fd = open('../app/static/data/points_new_fill.geojson', 'r')\n",
    "geojson = json.load(fd)\n",
    "df = pd.DataFrame(columns=['coords', 'time', 'dis', 'temp'])\n",
    "n_pred = 12\n",
    "for j in range(len(geojson['features'])):\n",
    "    coord = (geojson['features'][j]['geometry']['coordinates'][1], geojson['features'][j]['geometry']['coordinates'][0])\n",
    "    reduced_df = df_prediction.loc[coord, :]\n",
    "    #creating the datasets to train the model for the temperature\n",
    "    X_t, y_t = df_to_supervised_temperature(reduced_df.drop(columns=['prec', 'discharge']))\n",
    "\n",
    "    #splitting\n",
    "    n = len(X_t)\n",
    "    X_train, y_train = X_t[0:int(n*0.7)], y_t[0:int(n*0.7)]\n",
    "    X_val, y_val = X_t[int(n*0.7):], y_t[int(n*0.7):]\n",
    "    #it trains better on unscaled data\n",
    "    model_tmp = Sequential()\n",
    "    model_tmp.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model_tmp.add(Dense(12))\n",
    "    model_tmp.add(Dense(1))\n",
    "\n",
    "    model_tmp.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.1), metrics=[RootMeanSquaredError()])\n",
    "    model_tmp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10000, verbose=0, callbacks=[stop])\n",
    "    #saving the model inside the directory\n",
    "        \n",
    "    #creating the datasets to train the model for the discharge\n",
    "    X_d, y_d = df_to_supervised_discharge(reduced_df.drop(columns=['prec']))\n",
    "\n",
    "    #splitting\n",
    "    n = len(X_d)\n",
    "    X_train, y_train = X_d[0:int(n*0.7)], y_d[0:int(n*0.7)]\n",
    "    X_val, y_val = X_d[int(n*0.7):], y_d[int(n*0.7):]\n",
    "\n",
    "    #normalizing\n",
    "    X_mean = X_train.mean()\n",
    "    X_std = X_train.std()\n",
    "    X_train_sc = (X_train - X_mean) / X_std\n",
    "    X_val_sc = (X_val - X_mean) / X_std\n",
    "\n",
    "    y_mean = y_train.mean()\n",
    "    y_std = y_train.std()\n",
    "    y_train_sc = (y_train - X_mean) / X_std\n",
    "    y_val_sc = (y_val - X_mean) / X_std\n",
    "    model_dis = Sequential()\n",
    "    model_dis.add(LSTM(32, input_shape=(X_train_sc.shape[1], X_train_sc.shape[2])))\n",
    "    model_dis.add(Dense(12))\n",
    "    model_dis.add(Dense(1))\n",
    "\n",
    "    model_dis.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])\n",
    "    model_dis.fit(X_train_sc, y_train_sc, validation_data=(X_val_sc, y_val_sc), epochs=10000, verbose=0, callbacks=[stop])\n",
    "\n",
    "    #creating the new dataset from the last value to predict the future\n",
    "    X_tmp, last_time = create_future_df(reduced_df.drop(columns=['prec', 'discharge']))\n",
    "    X_dis, _ = create_future_df(reduced_df.drop(columns=['prec']))\n",
    "    X_dis_sc = (X_dis - X_mean) / X_std\n",
    "    #structure to save the prediction results\n",
    "    tmp_pred_ls = []\n",
    "    dis_pred_ls = []\n",
    "    time = []\n",
    "    coords = []\n",
    "    #predicting\n",
    "    for i in range(n_pred):\n",
    "        tmp_pred = model_tmp.predict(X_tmp).flatten()[0]\n",
    "        dis_pred = model_dis.predict(X_dis_sc).flatten()[0]\n",
    "        dis_pred = (dis_pred*X_std)+X_mean\n",
    "        tmp_pred_ls.append(tmp_pred)\n",
    "        if(dis_pred < 0):\n",
    "            dis_pred_ls.append(0)\n",
    "        else:\n",
    "            dis_pred_ls.append(dis_pred)\n",
    "        time.append(last_time)\n",
    "        coords.append(coord)\n",
    "        X_tmp, _ = append_row_tmp(X_tmp, last_time, tmp_pred)\n",
    "        X_dis, last_time = append_row_dis(X_dis, last_time, tmp_pred, dis_pred)\n",
    "        X_dis_sc = (X_dis - X_mean) / X_std\n",
    "\n",
    "    data = {'coords': coords, 'time': time, 'dis':dis_pred_ls, 'temp':tmp_pred_ls}\n",
    "    df = pd.concat([df,  pd.DataFrame(data=data)])\n",
    "    del model_tmp\n",
    "    del model_dis\n",
    "df.to_pickle(parent+'/grouped_pred.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e91d7251fb344e996def3e92284d431619133ca817cffa03ab54840799a3500"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
