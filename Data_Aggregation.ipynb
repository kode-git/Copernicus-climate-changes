{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./src/copernicus-logo.png\"><span style=\"margin-left: 40px\"></span><img src=\"./src/cds-logo.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Aggregation phase will integrates data from the same time and the same geographical references in a pandas dataset. The result will be a series of CSV files with discharges, temperatures and precipitations on a part of Italy that will be our domain of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integration between TPI and RDH "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyVC-fT4-E-8"
      },
      "outputs": [],
      "source": [
        "import netCDF4\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "jsonFileR = open(\"./samples/map-italy-loc.json\", \"r\") # file with the i.j indexes for the lat lon inside the north italy rectangle, saved in the same directory of coordinates\n",
        "ljson = json.load(jsonFileR)\n",
        "jsonFileR.close()\n",
        "\n",
        "i_dim = 949 # index of the last element for temperature and precipitation since in a file i goes from 0 to 949 and in the other two it goes from 949 to 0\n",
        "\n",
        "#header for the csv file\n",
        "header = ['time', 'lat', 'lon', 'discharge', 'temp', 'prec']\n",
        "\n",
        "\n",
        "d_years = ['2013-2014-2', '2015-2016-3', '2017-2018-4', '2019-2020-5', '2021-2022-6'] # years in the discharge file\n",
        "p_t_years = ['2013-8', '2014-9', '2015-10', '2016-11', '2017-12', '2018-13', '2019-14', '2020-15', '2021-16'] # years in the temperature and precipitation file\n",
        "d_years = d_years[2]\n",
        "p_t_years = p_t_years[4:5]\n",
        "\n",
        "for idf_d in range(0, len(d_years)):\n",
        "#Edit file path\n",
        "    nc_d = netCDF4.Dataset('./cs3-copernicus-precipitation-temp-on-river-discharges/cs3-copernicus-river-discharges-daily-18-2011-2021/rdh-'+d_years[idf_d] +'.nc')\n",
        "    #for each discharge file there are two yers of temperature and precipitation files, so they are indexed adding to the index of the discharge file\n",
        "    for idf_d_t in range(0, 2):\n",
        "        year = p_t_years[idf_d+idf_d_t]\n",
        "        nc_p = netCDF4.Dataset('./cs3-copernicus-precipitation-temp-on-river-discharges/cs3-copernicus-temperatures-and-precipitations-2006-2025/tpi-prec-' + year + '.nc')\n",
        "        nc_t = netCDF4.Dataset('./cs3-copernicus-precipitation-temp-on-river-discharges/cs3-copernicus-temperatures-and-precipitations-2006-2025/tpi-temp-' + year + '.nc')\n",
        "\n",
        "        #variables that need to be saved, avoiding to have too many indexes later\n",
        "        #the time for the timestamp is taken from the precipitation file\n",
        "        time_var = nc_p.variables['time']\n",
        "        dtime = netCDF4.num2date(time_var[:],time_var.units)\n",
        "        discharge = nc_d.variables['dis06']\n",
        "        lat = nc_d.variables['latitude']\n",
        "        lon = nc_d.variables['longitude']\n",
        "        temp = nc_t.variables['tasAdjust']\n",
        "        prec = nc_p.variables['prAdjust']\n",
        "        #for each year write the header of the csv file\n",
        "        ds = pd.DataFrame(data = [], columns = header)\n",
        "        ds.to_csv('italy-dtp-' + year + '.csv', mode='w', index=True)\n",
        "        #for each timestamp (so for each day) create a new empty dataframe\n",
        "        for l in ljson:\n",
        "            ds = pd.DataFrame(data = [], columns=header)\n",
        "            len_ds = len(ds)\n",
        "            #NOTICE: se vogliamo il dataframe con i valori per la stessa coordinata per tutti i giorni diversi messi in righe consecutive bisogna invertire i due for\n",
        "            #Ora il dataframe è una cosa del tipo\n",
        "            #time, lat_i, lon_j\n",
        "            #time, lat_i+n, lon_j+m (ci sono n e m perchè sono stati tolti i valori nan, quindi potrebbero non essere consecutive anche se improbabile)\n",
        "            #se invece invertiamo i for diventa\n",
        "            #time, lat_i, lon_j\n",
        "            #time+1, lat_i, lon_j\n",
        "            #time+2, lat_i, lon_j\n",
        "            #...\n",
        "            #quindi decidi come è meglio, perchè io ho iniziato in questo modo ma non so se per l'analisi che dobbiamo fare noi conviene nell'altro\n",
        "            #for each coordinate in the rectangle add a new row to the dataframe with the desired value\n",
        "            for t in range(0, len(dtime)):\n",
        "                ds.loc[len_ds] = [dtime[t], lat[l[0]][l[1]], lon[l[0]][l[1]], discharge[t+(365*idf_d_t)][l[0]][l[1]], temp[t][i_dim-l[0]][l[1]]-273.15, prec[t][i_dim-l[0]][l[1]]]\n",
        "                len_ds += 1\n",
        "            #when the timestamp is done write the dataframe to the file, without the header\n",
        "            ds.to_csv('italy-dtp-' + year + '.csv', mode='a', index=True, header=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Data_Aggregation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
